{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from os import path as op\n",
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "data_path = os.getcwd()+ \"/\"\n",
    "batch_size = 100\n",
    "num_cpus = 0\n",
    "num_gpus = 1\n",
    "\n",
    "def prep_data(data_path):\n",
    "    \"\"\"\n",
    "    Convert numpy array to mx Nd-array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the directory that save data.npz.\n",
    "    \"\"\"\n",
    "    data = np.load(find_file(data_path, 'data.npz'))\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    x_train -= np.mean(x_train)\n",
    "    x_train /= np.std(x_train)\n",
    "    x_test -= np.mean(x_train)\n",
    "    x_test /= np.std(x_train)\n",
    "\n",
    "    img_rows = 256\n",
    "    img_cols = 256\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    # y_train = y_train.reshape(y_train.shape[0], )\n",
    "    # y_test = y_test.reshape(y_test.shape[0], )\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    train_iter = mx.io.NDArrayIter(x_train, y_train, batch_size, shuffle=True)\n",
    "    val_iter = mx.io.NDArrayIter(x_test, y_test, batch_size)\n",
    "\n",
    "    return train_iter, val_iter\n",
    "\n",
    "def find_file(root_path, file_name):\n",
    "    \"\"\"\n",
    "    Searching for data.npz at its root director, and return a full path for the file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path: the root directory for data.npz.\n",
    "    file_name: refers to data.npz\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        if file_name in files:\n",
    "            return os.path.join(root, file_name)\n",
    "\n",
    "def mx_lenet():\n",
    "    \"\"\"Building a two layer LeNet Convolutional Neural Net using MXNet.\"\"\"\n",
    "    data = mx.sym.var('data')\n",
    "    # first conv layer\n",
    "    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)\n",
    "    tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # second conv layer\n",
    "    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # first fullc layer\n",
    "    flatten = mx.sym.flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=2)\n",
    "    # softmax loss\n",
    "    return mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "\n",
    "\n",
    "def train(num_cpus, num_gpus, **kwargs):\n",
    "    \"\"\"\n",
    "    Train the image classification neural net.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    train_iter, val_iter = prep_data(data_path)\n",
    "    lenet = mx_lenet()\n",
    "    lenet_model = mx.mod.Module(\n",
    "        symbol=lenet,\n",
    "        context=get_train_context(num_cpus, num_gpus))\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    lenet_model.fit(train_iter,\n",
    "                    eval_data=val_iter,\n",
    "                    optimizer='sgd',\n",
    "                    optimizer_params={'learning_rate': 0.1},\n",
    "                    eval_metric='acc',\n",
    "                    batch_end_callback=mx.callback.Speedometer(batch_size, 16),\n",
    "                    num_epoch=50)\n",
    "    return lenet_model\n",
    "\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    \"\"\"\n",
    "    Define the model training instance.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    if num_gpus > 0:\n",
    "        return mx.gpu()\n",
    "    return mx.cpu()\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    if num_gpus > 0:\n",
    "        print(\"It's {} instance\".format(num_gpus))\n",
    "        return mx.gpu()\n",
    "    print(\"It's {} instance\".format(num_cpus))\n",
    "    return mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-552819999234\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-gpu-2018-01-11-14-27-17-798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:04,904 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:04,904 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:06,669 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'mx_lenet_sagemaker.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'mx_lenet_sagemaker.py', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-14-27-17-798/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-py2-gpu-2018-01-11-14-27-17-798', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-14-27-17-798/source/sourcedir.tar.gz', 'sagemaker_region': u'us-east-1', 'input_dir': '/opt/ml/input', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-14-27-17-798/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:06,798 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:06,923 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m((448, 3, 256, 256), (112, 3, 256, 256), (448, 2), (112, 2))\u001b[0m\n",
      "\u001b[31mIt's 1 instance\u001b[0m\n",
      "\u001b[31m[14:34:15] src/operator/././cudnn_algoreg-inl.h:106: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py:630: DeprecationWarning: generator 'multi_stream_iter' raised StopIteration\n",
      "  for idx, event in sagemaker.logs.multi_stream_iter(client, log_group, stream_names, positions):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-01-11 14:34:20,540 INFO - root - Epoch[0] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:20,541 INFO - root - Epoch[0] Time cost=3.190\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:22,306 INFO - root - Epoch[0] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:23,952 INFO - root - Epoch[1] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:23,952 INFO - root - Epoch[1] Time cost=1.646\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:25,696 INFO - root - Epoch[1] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:27,343 INFO - root - Epoch[2] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:27,343 INFO - root - Epoch[2] Time cost=1.647\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:29,102 INFO - root - Epoch[2] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:30,751 INFO - root - Epoch[3] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:30,752 INFO - root - Epoch[3] Time cost=1.650\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:32,507 INFO - root - Epoch[3] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:34,156 INFO - root - Epoch[4] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:34,156 INFO - root - Epoch[4] Time cost=1.649\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:35,916 INFO - root - Epoch[4] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:37,566 INFO - root - Epoch[5] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:37,567 INFO - root - Epoch[5] Time cost=1.650\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:39,340 INFO - root - Epoch[5] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:40,988 INFO - root - Epoch[6] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:40,989 INFO - root - Epoch[6] Time cost=1.648\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:42,754 INFO - root - Epoch[6] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:44,404 INFO - root - Epoch[7] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:44,404 INFO - root - Epoch[7] Time cost=1.650\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:46,173 INFO - root - Epoch[7] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:47,825 INFO - root - Epoch[8] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:47,825 INFO - root - Epoch[8] Time cost=1.652\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:49,586 INFO - root - Epoch[8] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:51,237 INFO - root - Epoch[9] Train-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:51,237 INFO - root - Epoch[9] Time cost=1.651\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:52,995 INFO - root - Epoch[9] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:54,641 INFO - root - Epoch[10] Train-accuracy=0.557000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:54,641 INFO - root - Epoch[10] Time cost=1.646\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:56,396 INFO - root - Epoch[10] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:58,040 INFO - root - Epoch[11] Train-accuracy=0.524000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:58,040 INFO - root - Epoch[11] Time cost=1.644\u001b[0m\n",
      "\u001b[31m2018-01-11 14:34:59,817 INFO - root - Epoch[11] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:01,454 INFO - root - Epoch[12] Train-accuracy=0.471000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:01,454 INFO - root - Epoch[12] Time cost=1.637\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:03,217 INFO - root - Epoch[12] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:04,864 INFO - root - Epoch[13] Train-accuracy=0.528000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:04,864 INFO - root - Epoch[13] Time cost=1.647\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:06,624 INFO - root - Epoch[13] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:08,274 INFO - root - Epoch[14] Train-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:08,274 INFO - root - Epoch[14] Time cost=1.650\u001b[0m\n",
      "\u001b[31m2018-01-11 14:35:10,047 INFO - root - Epoch[14] Validation-accuracy=0.430000\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f83784e92a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mtrain_instance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ml.p2.xlarge\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         train_instance_count=1)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmxnet_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://ds-skynet/MX-Net/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJOB_NAME_PARAM_NAME\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSAGEMAKER_REGION_PARAM_NAME\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFramework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Asynchronous fit not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# print(\"Your Role is {}\".format())\n",
    "mxnet_estimator = MXNet(\"mx_lenet_sagemaker.py\", \n",
    "                        role=get_execution_role(), \n",
    "                        train_instance_type=\"ml.p2.xlarge\", \n",
    "                        train_instance_count=1)\n",
    "mxnet_estimator.fit(\"s3://ds-skynet/MX-Net/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
