{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mx_lenet_sagemaker.py\n"
     ]
    }
   ],
   "source": [
    "%%file mx_lenet_sagemaker.py\n",
    "import logging\n",
    "from os import path as op\n",
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "data_path = os.getcwd()+ \"/\"\n",
    "batch_size = 100\n",
    "num_cpus = 0\n",
    "num_gpus = 1\n",
    "\n",
    "def prep_data(data_path):\n",
    "    \"\"\"\n",
    "    Convert numpy array to mx Nd-array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the directory that save data.npz.\n",
    "    \"\"\"\n",
    "    data = np.load(find_file(data_path, 'data.npz'))\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train'][:,1:]\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test'][:,1:]\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    x_train -= np.mean(x_train)\n",
    "    x_train /= np.std(x_train)\n",
    "    x_test -= np.mean(x_train)\n",
    "    x_test /= np.std(x_train)\n",
    "\n",
    "    img_rows = 256\n",
    "    img_cols = 256\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    y_train = y_train.reshape(y_train.shape[0], )\n",
    "    y_test = y_test.reshape(y_test.shape[0], )\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    train_iter = mx.io.NDArrayIter(x_train, y_train, batch_size, shuffle=True)\n",
    "    val_iter = mx.io.NDArrayIter(x_test, y_test, batch_size)\n",
    "\n",
    "    return train_iter, val_iter\n",
    "\n",
    "def find_file(root_path, file_name):\n",
    "    \"\"\"\n",
    "    Searching for data.npz at its root director, and return a full path for the file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path: the root directory for data.npz.\n",
    "    file_name: refers to data.npz\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        if file_name in files:\n",
    "            return os.path.join(root, file_name)\n",
    "\n",
    "def mx_lenet():\n",
    "    \"\"\"Building a two layer LeNet Convolutional Neural Net using MXNet.\"\"\"\n",
    "    data = mx.sym.var('data')\n",
    "    # first conv layer\n",
    "    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)\n",
    "    tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # second conv layer\n",
    "    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # first fullc layer\n",
    "    flatten = mx.sym.flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=2)\n",
    "    # softmax loss\n",
    "    return mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "\n",
    "\n",
    "def train(num_cpus, num_gpus, **kwargs):\n",
    "    \"\"\"\n",
    "    Train the image classification neural net.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    train_iter, val_iter = prep_data(data_path)\n",
    "    lenet = mx_lenet()\n",
    "    lenet_model = mx.mod.Module(\n",
    "        symbol=lenet,\n",
    "        context=get_train_context(num_cpus, num_gpus))\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    lenet_model.fit(train_iter,\n",
    "                    eval_data=val_iter,\n",
    "                    optimizer='sgd',\n",
    "                    optimizer_params={'learning_rate': 0.1},\n",
    "                    eval_metric='acc',\n",
    "                    batch_end_callback=mx.callback.Speedometer(batch_size, 16),\n",
    "                    num_epoch=50)\n",
    "    return lenet_model\n",
    "\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    \"\"\"\n",
    "    Define the model training instance.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    if num_gpus > 0:\n",
    "        return mx.gpu()\n",
    "    return mx.cpu()\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    if num_gpus > 0:\n",
    "        print(\"It's {} instance\".format(num_gpus))\n",
    "        return mx.gpu()\n",
    "    print(\"It's {} instance\".format(num_cpus))\n",
    "    return mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-552819999234\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-gpu-2018-01-11-18-26-16-705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:15,142 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:15,142 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:16,952 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'mx_lenet_sagemaker.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'mx_lenet_sagemaker.py', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-26-16-705/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-py2-gpu-2018-01-11-18-26-16-705', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-26-16-705/source/sourcedir.tar.gz', 'sagemaker_region': u'us-east-1', 'input_dir': '/opt/ml/input', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-26-16-705/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:17,083 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:17,198 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m((448, 3, 256, 256), (112, 3, 256, 256), (448,), (112,))\u001b[0m\n",
      "\u001b[31mIt's 1 instance\u001b[0m\n",
      "\u001b[31m[18:33:24] src/operator/././cudnn_algoreg-inl.h:106: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:30,321 INFO - root - Epoch[0] Train-accuracy=0.522000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:30,321 INFO - root - Epoch[0] Time cost=3.054\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:31,872 INFO - root - Epoch[0] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:33,488 INFO - root - Epoch[1] Train-accuracy=0.576000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:33,488 INFO - root - Epoch[1] Time cost=1.615\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:35,011 INFO - root - Epoch[1] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:36,629 INFO - root - Epoch[2] Train-accuracy=0.606000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:36,630 INFO - root - Epoch[2] Time cost=1.619\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:38,137 INFO - root - Epoch[2] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:39,754 INFO - root - Epoch[3] Train-accuracy=0.610000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:39,754 INFO - root - Epoch[3] Time cost=1.617\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:41,280 INFO - root - Epoch[3] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:42,895 INFO - root - Epoch[4] Train-accuracy=0.608000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:42,895 INFO - root - Epoch[4] Time cost=1.614\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:44,408 INFO - root - Epoch[4] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:46,028 INFO - root - Epoch[5] Train-accuracy=0.648000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:46,029 INFO - root - Epoch[5] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:47,564 INFO - root - Epoch[5] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:49,183 INFO - root - Epoch[6] Train-accuracy=0.650000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:49,183 INFO - root - Epoch[6] Time cost=1.619\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:50,712 INFO - root - Epoch[6] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:52,330 INFO - root - Epoch[7] Train-accuracy=0.560000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:52,330 INFO - root - Epoch[7] Time cost=1.617\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:53,852 INFO - root - Epoch[7] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:55,471 INFO - root - Epoch[8] Train-accuracy=0.664000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:55,472 INFO - root - Epoch[8] Time cost=1.620\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:56,995 INFO - root - Epoch[8] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:58,615 INFO - root - Epoch[9] Train-accuracy=0.682000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:33:58,615 INFO - root - Epoch[9] Time cost=1.620\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:00,146 INFO - root - Epoch[9] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:01,761 INFO - root - Epoch[10] Train-accuracy=0.664000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:01,761 INFO - root - Epoch[10] Time cost=1.615\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:03,271 INFO - root - Epoch[10] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:04,892 INFO - root - Epoch[11] Train-accuracy=0.680000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:04,892 INFO - root - Epoch[11] Time cost=1.622\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:06,422 INFO - root - Epoch[11] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:08,046 INFO - root - Epoch[12] Train-accuracy=0.692000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:08,047 INFO - root - Epoch[12] Time cost=1.624\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:09,569 INFO - root - Epoch[12] Validation-accuracy=0.550000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:11,184 INFO - root - Epoch[13] Train-accuracy=0.590000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:11,185 INFO - root - Epoch[13] Time cost=1.616\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:12,707 INFO - root - Epoch[13] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:14,328 INFO - root - Epoch[14] Train-accuracy=0.514000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:14,328 INFO - root - Epoch[14] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:15,862 INFO - root - Epoch[14] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:17,480 INFO - root - Epoch[15] Train-accuracy=0.524000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:17,480 INFO - root - Epoch[15] Time cost=1.618\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:19,007 INFO - root - Epoch[15] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:20,619 INFO - root - Epoch[16] Train-accuracy=0.502000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:20,619 INFO - root - Epoch[16] Time cost=1.612\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:22,151 INFO - root - Epoch[16] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:23,792 INFO - root - Epoch[17] Train-accuracy=0.534000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:23,792 INFO - root - Epoch[17] Time cost=1.641\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:25,266 INFO - root - Epoch[17] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:26,886 INFO - root - Epoch[18] Train-accuracy=0.542000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:26,886 INFO - root - Epoch[18] Time cost=1.620\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:28,423 INFO - root - Epoch[18] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:30,040 INFO - root - Epoch[19] Train-accuracy=0.530000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:30,040 INFO - root - Epoch[19] Time cost=1.617\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:31,583 INFO - root - Epoch[19] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:33,206 INFO - root - Epoch[20] Train-accuracy=0.550000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:33,206 INFO - root - Epoch[20] Time cost=1.623\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:34,722 INFO - root - Epoch[20] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:36,345 INFO - root - Epoch[21] Train-accuracy=0.640000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:36,345 INFO - root - Epoch[21] Time cost=1.622\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:37,889 INFO - root - Epoch[21] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:39,508 INFO - root - Epoch[22] Train-accuracy=0.524000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:39,509 INFO - root - Epoch[22] Time cost=1.619\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:41,026 INFO - root - Epoch[22] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:42,648 INFO - root - Epoch[23] Train-accuracy=0.522000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:42,648 INFO - root - Epoch[23] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:44,168 INFO - root - Epoch[23] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:45,786 INFO - root - Epoch[24] Train-accuracy=0.530000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:45,786 INFO - root - Epoch[24] Time cost=1.619\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:47,298 INFO - root - Epoch[24] Validation-accuracy=0.430000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-01-11 18:34:48,919 INFO - root - Epoch[25] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:48,919 INFO - root - Epoch[25] Time cost=1.620\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:50,449 INFO - root - Epoch[25] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:52,070 INFO - root - Epoch[26] Train-accuracy=0.552000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:52,070 INFO - root - Epoch[26] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:53,575 INFO - root - Epoch[26] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:55,199 INFO - root - Epoch[27] Train-accuracy=0.560000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:55,199 INFO - root - Epoch[27] Time cost=1.623\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:56,710 INFO - root - Epoch[27] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:58,335 INFO - root - Epoch[28] Train-accuracy=0.592000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:58,335 INFO - root - Epoch[28] Time cost=1.625\u001b[0m\n",
      "\u001b[31m2018-01-11 18:34:59,860 INFO - root - Epoch[28] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:01,481 INFO - root - Epoch[29] Train-accuracy=0.566000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:01,481 INFO - root - Epoch[29] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:03,005 INFO - root - Epoch[29] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:04,626 INFO - root - Epoch[30] Train-accuracy=0.582000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:04,626 INFO - root - Epoch[30] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:06,157 INFO - root - Epoch[30] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:07,777 INFO - root - Epoch[31] Train-accuracy=0.532000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:07,777 INFO - root - Epoch[31] Time cost=1.620\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:09,306 INFO - root - Epoch[31] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:10,934 INFO - root - Epoch[32] Train-accuracy=0.596000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:10,934 INFO - root - Epoch[32] Time cost=1.628\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:12,468 INFO - root - Epoch[32] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:14,090 INFO - root - Epoch[33] Train-accuracy=0.510000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:14,090 INFO - root - Epoch[33] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:15,614 INFO - root - Epoch[33] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:17,236 INFO - root - Epoch[34] Train-accuracy=0.552000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:17,236 INFO - root - Epoch[34] Time cost=1.622\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:18,781 INFO - root - Epoch[34] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:20,406 INFO - root - Epoch[35] Train-accuracy=0.638000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:20,406 INFO - root - Epoch[35] Time cost=1.625\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:21,935 INFO - root - Epoch[35] Validation-accuracy=0.575000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:23,557 INFO - root - Epoch[36] Train-accuracy=0.534000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:23,557 INFO - root - Epoch[36] Time cost=1.622\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:25,073 INFO - root - Epoch[36] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:26,697 INFO - root - Epoch[37] Train-accuracy=0.606000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:26,697 INFO - root - Epoch[37] Time cost=1.624\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:28,213 INFO - root - Epoch[37] Validation-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:29,841 INFO - root - Epoch[38] Train-accuracy=0.564000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:29,841 INFO - root - Epoch[38] Time cost=1.628\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:31,365 INFO - root - Epoch[38] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:32,986 INFO - root - Epoch[39] Train-accuracy=0.550000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:32,986 INFO - root - Epoch[39] Time cost=1.621\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:34,499 INFO - root - Epoch[39] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:36,124 INFO - root - Epoch[40] Train-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:36,124 INFO - root - Epoch[40] Time cost=1.625\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:37,637 INFO - root - Epoch[40] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:39,263 INFO - root - Epoch[41] Train-accuracy=0.602000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:39,263 INFO - root - Epoch[41] Time cost=1.626\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:40,801 INFO - root - Epoch[41] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:42,424 INFO - root - Epoch[42] Train-accuracy=0.544000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:42,424 INFO - root - Epoch[42] Time cost=1.623\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:43,964 INFO - root - Epoch[42] Validation-accuracy=0.540000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:45,592 INFO - root - Epoch[43] Train-accuracy=0.608000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:45,592 INFO - root - Epoch[43] Time cost=1.628\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:47,129 INFO - root - Epoch[43] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:48,755 INFO - root - Epoch[44] Train-accuracy=0.576000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:48,755 INFO - root - Epoch[44] Time cost=1.625\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:50,282 INFO - root - Epoch[44] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:51,911 INFO - root - Epoch[45] Train-accuracy=0.586000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:51,911 INFO - root - Epoch[45] Time cost=1.629\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:53,447 INFO - root - Epoch[45] Validation-accuracy=0.570000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:55,076 INFO - root - Epoch[46] Train-accuracy=0.610000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:55,076 INFO - root - Epoch[46] Time cost=1.628\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:56,587 INFO - root - Epoch[46] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:58,215 INFO - root - Epoch[47] Train-accuracy=0.544000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:58,215 INFO - root - Epoch[47] Time cost=1.628\u001b[0m\n",
      "\u001b[31m2018-01-11 18:35:59,730 INFO - root - Epoch[47] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:01,361 INFO - root - Epoch[48] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:01,361 INFO - root - Epoch[48] Time cost=1.632\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:02,877 INFO - root - Epoch[48] Validation-accuracy=0.430000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:04,503 INFO - root - Epoch[49] Train-accuracy=0.568000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:04,503 INFO - root - Epoch[49] Time cost=1.626\u001b[0m\n",
      "\u001b[31m2018-01-11 18:36:06,004 INFO - root - Epoch[49] Validation-accuracy=0.430000\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "mxnet_estimator = MXNet(\"mx_lenet_sagemaker.py\", \n",
    "                        role=get_execution_role(), \n",
    "                        train_instance_type=\"ml.p2.xlarge\", \n",
    "                        train_instance_count=1)\n",
    "mxnet_estimator.fit(\"s3://ds-skynet/MX-Net/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
