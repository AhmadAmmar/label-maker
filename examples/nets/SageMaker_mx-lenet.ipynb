{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mx_lenet_sagemaker.py\n"
     ]
    }
   ],
   "source": [
    "%%file mx_lenet_sagemaker.py\n",
    "import logging\n",
    "from os import path as op\n",
    "import os\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "data_path = os.getcwd()+ \"/\"\n",
    "batch_size = 50\n",
    "num_cpus = 0\n",
    "num_gpus = 1\n",
    "\n",
    "def prep_data(data_path):\n",
    "    \"\"\"\n",
    "    Convert numpy array to mx Nd-array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the directory that save data.npz.\n",
    "    \"\"\"\n",
    "    data = np.load(find_file(data_path, 'data.npz'))\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train'][:,:1] ## only take the second column of y_train\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test'][:,:1]\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    x_train -= np.mean(x_train)\n",
    "    x_train /= np.std(x_train)\n",
    "    x_test -= np.mean(x_train)\n",
    "    x_test /= np.std(x_train)\n",
    "\n",
    "    img_rows = 256\n",
    "    img_cols = 256\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols) ## reshape it to (448, ) instead of (448,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    y_train = y_train.reshape(y_train.shape[0], )\n",
    "    y_test = y_test.reshape(y_test.shape[0], )\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    train_iter = mx.io.NDArrayIter(x_train, y_train, batch_size, shuffle=True)\n",
    "    val_iter = mx.io.NDArrayIter(x_test, y_test, batch_size)\n",
    "\n",
    "    return train_iter, val_iter\n",
    "\n",
    "def find_file(root_path, file_name):\n",
    "    \"\"\"\n",
    "    Searching for data.npz at its root director, and return a full path for the file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path: the root directory for data.npz.\n",
    "    file_name: refers to data.npz\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        if file_name in files:\n",
    "            return os.path.join(root, file_name)\n",
    "\n",
    "def mx_lenet():\n",
    "    \"\"\"Building a two layer LeNet Convolutional Neural Net using MXNet.\"\"\"\n",
    "    data = mx.sym.var('data')\n",
    "    # first conv layer\n",
    "    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)\n",
    "    tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # second conv layer\n",
    "    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # first fullc layer\n",
    "    flatten = mx.sym.flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=2)\n",
    "    # softmax loss\n",
    "    return mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "\n",
    "\n",
    "def train(num_cpus, num_gpus, **kwargs):\n",
    "    \"\"\"\n",
    "    Train the image classification neural net.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    train_iter, val_iter = prep_data(data_path)\n",
    "    lenet = mx_lenet()\n",
    "    lenet_model = mx.mod.Module(\n",
    "        symbol=lenet,\n",
    "        context=get_train_context(num_cpus, num_gpus))\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    lenet_model.fit(train_iter,\n",
    "                    eval_data=val_iter,\n",
    "                    optimizer='sgd',\n",
    "                    optimizer_params={'learning_rate': 0.1},\n",
    "                    eval_metric='acc',\n",
    "                    batch_end_callback=mx.callback.Speedometer(batch_size, 16),\n",
    "                    num_epoch=80)\n",
    "    return lenet_model\n",
    "\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    \"\"\"\n",
    "    Define the model training instance.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_cpus: If train the model on an aws GPS machine, num_cpus = 0 and num_gpus = 1, vice versa.\n",
    "    num_gpus: apply to the same rule above\n",
    "    \"\"\"\n",
    "    if num_gpus > 0:\n",
    "        return mx.gpu()\n",
    "    return mx.cpu()\n",
    "\n",
    "def get_train_context(num_cpus, num_gpus):\n",
    "    if num_gpus > 0:\n",
    "        print(\"It's {} instance\".format(num_gpus))\n",
    "        return mx.gpu()\n",
    "    print(\"It's {} instance\".format(num_cpus))\n",
    "    return mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-552819999234\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-gpu-2018-01-11-18-52-53-404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:37,357 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:37,357 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:39,209 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'mx_lenet_sagemaker.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'mx_lenet_sagemaker.py', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-52-53-404/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-py2-gpu-2018-01-11-18-52-53-404', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-52-53-404/source/sourcedir.tar.gz', 'sagemaker_region': u'us-east-1', 'input_dir': '/opt/ml/input', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-552819999234/sagemaker-mxnet-py2-gpu-2018-01-11-18-52-53-404/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:39,354 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:39,475 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m((448, 3, 256, 256), (112, 3, 256, 256), (448,), (112,))\u001b[0m\n",
      "\u001b[31mIt's 1 instance\u001b[0m\n",
      "\u001b[31m[18:59:46] src/operator/././cudnn_algoreg-inl.h:106: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:50,851 INFO - root - Epoch[0] Train-accuracy=0.591111\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:50,852 INFO - root - Epoch[0] Time cost=2.952\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:52,278 INFO - root - Epoch[0] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:53,791 INFO - root - Epoch[1] Train-accuracy=0.600000\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:53,791 INFO - root - Epoch[1] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:55,206 INFO - root - Epoch[1] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:56,718 INFO - root - Epoch[2] Train-accuracy=0.573333\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:56,718 INFO - root - Epoch[2] Time cost=1.512\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:58,137 INFO - root - Epoch[2] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:59,654 INFO - root - Epoch[3] Train-accuracy=0.557778\u001b[0m\n",
      "\u001b[31m2018-01-11 18:59:59,655 INFO - root - Epoch[3] Time cost=1.518\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:01,067 INFO - root - Epoch[3] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:02,583 INFO - root - Epoch[4] Train-accuracy=0.608889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:02,584 INFO - root - Epoch[4] Time cost=1.516\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:04,002 INFO - root - Epoch[4] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:05,522 INFO - root - Epoch[5] Train-accuracy=0.593333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:05,522 INFO - root - Epoch[5] Time cost=1.520\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:06,934 INFO - root - Epoch[5] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:08,449 INFO - root - Epoch[6] Train-accuracy=0.664444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:08,449 INFO - root - Epoch[6] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:09,864 INFO - root - Epoch[6] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:11,386 INFO - root - Epoch[7] Train-accuracy=0.680000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:11,387 INFO - root - Epoch[7] Time cost=1.523\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:12,807 INFO - root - Epoch[7] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:14,332 INFO - root - Epoch[8] Train-accuracy=0.691111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:14,332 INFO - root - Epoch[8] Time cost=1.525\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:15,747 INFO - root - Epoch[8] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:17,272 INFO - root - Epoch[9] Train-accuracy=0.591111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:17,272 INFO - root - Epoch[9] Time cost=1.525\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:18,692 INFO - root - Epoch[9] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:20,219 INFO - root - Epoch[10] Train-accuracy=0.546667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:20,219 INFO - root - Epoch[10] Time cost=1.527\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:21,642 INFO - root - Epoch[10] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:23,166 INFO - root - Epoch[11] Train-accuracy=0.504444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:23,166 INFO - root - Epoch[11] Time cost=1.524\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:24,582 INFO - root - Epoch[11] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:26,111 INFO - root - Epoch[12] Train-accuracy=0.553333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:26,111 INFO - root - Epoch[12] Time cost=1.529\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:27,530 INFO - root - Epoch[12] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:29,058 INFO - root - Epoch[13] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:29,058 INFO - root - Epoch[13] Time cost=1.527\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:30,469 INFO - root - Epoch[13] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:31,994 INFO - root - Epoch[14] Train-accuracy=0.524444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:31,994 INFO - root - Epoch[14] Time cost=1.525\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:33,407 INFO - root - Epoch[14] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:34,935 INFO - root - Epoch[15] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:34,935 INFO - root - Epoch[15] Time cost=1.528\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:36,348 INFO - root - Epoch[15] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:37,877 INFO - root - Epoch[16] Train-accuracy=0.566667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:37,877 INFO - root - Epoch[16] Time cost=1.529\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:39,300 INFO - root - Epoch[16] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:40,826 INFO - root - Epoch[17] Train-accuracy=0.508889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:40,826 INFO - root - Epoch[17] Time cost=1.526\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:42,253 INFO - root - Epoch[17] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:43,776 INFO - root - Epoch[18] Train-accuracy=0.540000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:43,776 INFO - root - Epoch[18] Time cost=1.523\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:45,199 INFO - root - Epoch[18] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:46,721 INFO - root - Epoch[19] Train-accuracy=0.566667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:46,721 INFO - root - Epoch[19] Time cost=1.523\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:48,148 INFO - root - Epoch[19] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:49,670 INFO - root - Epoch[20] Train-accuracy=0.544444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:49,670 INFO - root - Epoch[20] Time cost=1.521\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:51,083 INFO - root - Epoch[20] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:52,615 INFO - root - Epoch[21] Train-accuracy=0.577778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:52,615 INFO - root - Epoch[21] Time cost=1.531\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:54,023 INFO - root - Epoch[21] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:55,542 INFO - root - Epoch[22] Train-accuracy=0.548889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:55,542 INFO - root - Epoch[22] Time cost=1.519\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:56,968 INFO - root - Epoch[22] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:58,483 INFO - root - Epoch[23] Train-accuracy=0.568889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:58,483 INFO - root - Epoch[23] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:00:59,899 INFO - root - Epoch[23] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:01,412 INFO - root - Epoch[24] Train-accuracy=0.553333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:01,412 INFO - root - Epoch[24] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:02,835 INFO - root - Epoch[24] Validation-accuracy=0.413333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-01-11 19:01:04,348 INFO - root - Epoch[25] Train-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:04,348 INFO - root - Epoch[25] Time cost=1.512\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:05,764 INFO - root - Epoch[25] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:07,274 INFO - root - Epoch[26] Train-accuracy=0.526667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:07,274 INFO - root - Epoch[26] Time cost=1.510\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:08,692 INFO - root - Epoch[26] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:10,203 INFO - root - Epoch[27] Train-accuracy=0.635556\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:10,204 INFO - root - Epoch[27] Time cost=1.511\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:11,636 INFO - root - Epoch[27] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:13,144 INFO - root - Epoch[28] Train-accuracy=0.553333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:13,144 INFO - root - Epoch[28] Time cost=1.508\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:14,570 INFO - root - Epoch[28] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:16,076 INFO - root - Epoch[29] Train-accuracy=0.577778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:16,076 INFO - root - Epoch[29] Time cost=1.506\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:17,497 INFO - root - Epoch[29] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:19,003 INFO - root - Epoch[30] Train-accuracy=0.602222\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:19,003 INFO - root - Epoch[30] Time cost=1.506\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:20,411 INFO - root - Epoch[30] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:21,916 INFO - root - Epoch[31] Train-accuracy=0.584444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:21,916 INFO - root - Epoch[31] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:23,344 INFO - root - Epoch[31] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:24,848 INFO - root - Epoch[32] Train-accuracy=0.615556\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:24,848 INFO - root - Epoch[32] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:26,271 INFO - root - Epoch[32] Validation-accuracy=0.693333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:27,775 INFO - root - Epoch[33] Train-accuracy=0.571111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:27,775 INFO - root - Epoch[33] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:29,199 INFO - root - Epoch[33] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:30,703 INFO - root - Epoch[34] Train-accuracy=0.584444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:30,703 INFO - root - Epoch[34] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:32,133 INFO - root - Epoch[34] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:33,637 INFO - root - Epoch[35] Train-accuracy=0.551111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:33,637 INFO - root - Epoch[35] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:35,056 INFO - root - Epoch[35] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:36,562 INFO - root - Epoch[36] Train-accuracy=0.577778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:36,562 INFO - root - Epoch[36] Time cost=1.505\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:37,984 INFO - root - Epoch[36] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:39,491 INFO - root - Epoch[37] Train-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:39,492 INFO - root - Epoch[37] Time cost=1.507\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:40,910 INFO - root - Epoch[37] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:42,417 INFO - root - Epoch[38] Train-accuracy=0.613333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:42,417 INFO - root - Epoch[38] Time cost=1.507\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:43,836 INFO - root - Epoch[38] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:45,342 INFO - root - Epoch[39] Train-accuracy=0.564444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:45,342 INFO - root - Epoch[39] Time cost=1.506\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:46,773 INFO - root - Epoch[39] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:48,278 INFO - root - Epoch[40] Train-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:48,278 INFO - root - Epoch[40] Time cost=1.504\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:49,699 INFO - root - Epoch[40] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:51,213 INFO - root - Epoch[41] Train-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:51,213 INFO - root - Epoch[41] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:52,631 INFO - root - Epoch[41] Validation-accuracy=0.626667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:54,143 INFO - root - Epoch[42] Train-accuracy=0.606667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:54,144 INFO - root - Epoch[42] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:55,561 INFO - root - Epoch[42] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:57,072 INFO - root - Epoch[43] Train-accuracy=0.620000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:57,072 INFO - root - Epoch[43] Time cost=1.511\u001b[0m\n",
      "\u001b[31m2018-01-11 19:01:58,494 INFO - root - Epoch[43] Validation-accuracy=0.420000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:00,008 INFO - root - Epoch[44] Train-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:00,008 INFO - root - Epoch[44] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:01,425 INFO - root - Epoch[44] Validation-accuracy=0.566667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:02,940 INFO - root - Epoch[45] Train-accuracy=0.600000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:02,940 INFO - root - Epoch[45] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:04,351 INFO - root - Epoch[45] Validation-accuracy=0.406667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:05,867 INFO - root - Epoch[46] Train-accuracy=0.648889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:05,868 INFO - root - Epoch[46] Time cost=1.517\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:07,292 INFO - root - Epoch[46] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:08,806 INFO - root - Epoch[47] Train-accuracy=0.591111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:08,806 INFO - root - Epoch[47] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:10,229 INFO - root - Epoch[47] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:11,744 INFO - root - Epoch[48] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:11,744 INFO - root - Epoch[48] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:13,177 INFO - root - Epoch[48] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:14,691 INFO - root - Epoch[49] Train-accuracy=0.584444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:14,692 INFO - root - Epoch[49] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:16,125 INFO - root - Epoch[49] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:17,645 INFO - root - Epoch[50] Train-accuracy=0.566667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:17,645 INFO - root - Epoch[50] Time cost=1.520\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:19,065 INFO - root - Epoch[50] Validation-accuracy=0.333333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:20,584 INFO - root - Epoch[51] Train-accuracy=0.575556\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:20,584 INFO - root - Epoch[51] Time cost=1.519\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:22,010 INFO - root - Epoch[51] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:23,529 INFO - root - Epoch[52] Train-accuracy=0.580000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:23,529 INFO - root - Epoch[52] Time cost=1.519\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:24,949 INFO - root - Epoch[52] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:26,467 INFO - root - Epoch[53] Train-accuracy=0.566667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:26,467 INFO - root - Epoch[53] Time cost=1.518\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:27,888 INFO - root - Epoch[53] Validation-accuracy=0.573333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:29,406 INFO - root - Epoch[54] Train-accuracy=0.617778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:29,406 INFO - root - Epoch[54] Time cost=1.518\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:30,818 INFO - root - Epoch[54] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:32,335 INFO - root - Epoch[55] Train-accuracy=0.564444\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:32,335 INFO - root - Epoch[55] Time cost=1.517\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:33,751 INFO - root - Epoch[55] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:35,268 INFO - root - Epoch[56] Train-accuracy=0.593333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:35,268 INFO - root - Epoch[56] Time cost=1.517\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:36,679 INFO - root - Epoch[56] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:38,195 INFO - root - Epoch[57] Train-accuracy=0.628889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:38,195 INFO - root - Epoch[57] Time cost=1.516\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:39,612 INFO - root - Epoch[57] Validation-accuracy=0.333333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:41,131 INFO - root - Epoch[58] Train-accuracy=0.666667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:41,131 INFO - root - Epoch[58] Time cost=1.519\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:42,551 INFO - root - Epoch[58] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:44,069 INFO - root - Epoch[59] Train-accuracy=0.548889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:44,069 INFO - root - Epoch[59] Time cost=1.517\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:45,484 INFO - root - Epoch[59] Validation-accuracy=0.346667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:47,000 INFO - root - Epoch[60] Train-accuracy=0.637778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:47,000 INFO - root - Epoch[60] Time cost=1.515\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-01-11 19:02:48,419 INFO - root - Epoch[60] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:49,932 INFO - root - Epoch[61] Train-accuracy=0.628889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:49,932 INFO - root - Epoch[61] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:51,354 INFO - root - Epoch[61] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:52,875 INFO - root - Epoch[62] Train-accuracy=0.633333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:52,875 INFO - root - Epoch[62] Time cost=1.521\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:54,304 INFO - root - Epoch[62] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:55,909 INFO - root - Epoch[63] Train-accuracy=0.640000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:55,909 INFO - root - Epoch[63] Time cost=1.605\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:57,333 INFO - root - Epoch[63] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:58,859 INFO - root - Epoch[64] Train-accuracy=0.608889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:02:58,860 INFO - root - Epoch[64] Time cost=1.527\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:00,298 INFO - root - Epoch[64] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:01,822 INFO - root - Epoch[65] Train-accuracy=0.597778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:01,823 INFO - root - Epoch[65] Time cost=1.524\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:03,257 INFO - root - Epoch[65] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:04,786 INFO - root - Epoch[66] Train-accuracy=0.597778\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:04,787 INFO - root - Epoch[66] Time cost=1.529\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:06,220 INFO - root - Epoch[66] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:07,751 INFO - root - Epoch[67] Train-accuracy=0.593333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:07,751 INFO - root - Epoch[67] Time cost=1.531\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:09,184 INFO - root - Epoch[67] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:10,722 INFO - root - Epoch[68] Train-accuracy=0.588889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:10,722 INFO - root - Epoch[68] Time cost=1.538\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:12,152 INFO - root - Epoch[68] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:13,669 INFO - root - Epoch[69] Train-accuracy=0.626667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:13,669 INFO - root - Epoch[69] Time cost=1.517\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:15,081 INFO - root - Epoch[69] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:16,595 INFO - root - Epoch[70] Train-accuracy=0.631111\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:16,595 INFO - root - Epoch[70] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:18,013 INFO - root - Epoch[70] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:19,525 INFO - root - Epoch[71] Train-accuracy=0.600000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:19,526 INFO - root - Epoch[71] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:20,942 INFO - root - Epoch[71] Validation-accuracy=0.426667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:22,456 INFO - root - Epoch[72] Train-accuracy=0.666667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:22,456 INFO - root - Epoch[72] Time cost=1.513\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:23,874 INFO - root - Epoch[72] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:25,389 INFO - root - Epoch[73] Train-accuracy=0.642222\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:25,389 INFO - root - Epoch[73] Time cost=1.515\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:26,805 INFO - root - Epoch[73] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:28,321 INFO - root - Epoch[74] Train-accuracy=0.648889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:28,321 INFO - root - Epoch[74] Time cost=1.516\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:29,737 INFO - root - Epoch[74] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:31,250 INFO - root - Epoch[75] Train-accuracy=0.588889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:31,250 INFO - root - Epoch[75] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:32,674 INFO - root - Epoch[75] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:34,188 INFO - root - Epoch[76] Train-accuracy=0.642222\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:34,188 INFO - root - Epoch[76] Time cost=1.514\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:35,617 INFO - root - Epoch[76] Validation-accuracy=0.426667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:37,138 INFO - root - Epoch[77] Train-accuracy=0.560000\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:37,138 INFO - root - Epoch[77] Time cost=1.521\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:38,565 INFO - root - Epoch[77] Validation-accuracy=0.413333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:40,085 INFO - root - Epoch[78] Train-accuracy=0.613333\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:40,085 INFO - root - Epoch[78] Time cost=1.520\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:41,507 INFO - root - Epoch[78] Validation-accuracy=0.586667\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:43,034 INFO - root - Epoch[79] Train-accuracy=0.628889\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:43,034 INFO - root - Epoch[79] Time cost=1.528\u001b[0m\n",
      "\u001b[31m2018-01-11 19:03:44,452 INFO - root - Epoch[79] Validation-accuracy=0.413333\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "mxnet_estimator = MXNet(\"mx_lenet_sagemaker.py\", \n",
    "                        role=get_execution_role(), \n",
    "                        train_instance_type=\"ml.p2.xlarge\", \n",
    "                        train_instance_count=1)\n",
    "mxnet_estimator.fit(\"s3://ds-skynet/MX-Net/data\") ## give your s3 bucket address here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
